{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zABIcHZtTFhh",
        "outputId": "797e828a-d2ba-47c5-9b31-75499699cf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX3s2ORkTNSP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import faiss\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvIU4BmiTjnz"
      },
      "outputs": [],
      "source": [
        "# Configurações\n",
        "MISTRAL_API_KEY = userdata.get(\"MISTRAL_KEY\")  # Substitua pela sua chave\n",
        "INPUT_FILE = \"/content/drive/MyDrive/Colab Notebooks/projeto II V3/scrapyFiles/biblioteca_dados_combinado.json\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/projeto II V3/scrapyFiles/faiss_index\"\n",
        "EMBEDDING_DIM = 1024  # Dimensão dos embeddings do modelo Mistral\n",
        "BASE_WAIT_TIME = 1.1  # Tempo base de espera entre requisições\n",
        "MAX_RETRIES = 5      # Número máximo de tentativas para cada livro\n",
        "\n",
        "# Criar diretório de saída, se não existir\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfxI-nERTrx-"
      },
      "outputs": [],
      "source": [
        "# Função para gerar embeddings usando a API da Mistral com retry e backoff\n",
        "def get_embedding_with_retry(text, api_key=MISTRAL_API_KEY, max_retries=MAX_RETRIES):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    url = \"https://api.mistral.ai/v1/embeddings\"\n",
        "    payload = {\n",
        "        \"model\": \"mistral-embed\",\n",
        "        \"input\": text\n",
        "    }\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()[\"data\"][0][\"embedding\"]\n",
        "            elif response.status_code == 429:\n",
        "                wait_time = BASE_WAIT_TIME * (2 ** attempt)\n",
        "                print(f\"Rate limit excedido. Tentativa {attempt+1}/{max_retries}. Aguardando {wait_time:.2f} segundos...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"Erro na API: {response.status_code}\")\n",
        "                print(response.text)\n",
        "                time.sleep(BASE_WAIT_TIME)\n",
        "        except Exception as e:\n",
        "            print(f\"Exceção ocorreu: {str(e)}\")\n",
        "            time.sleep(BASE_WAIT_TIME)\n",
        "\n",
        "    print(f\"Falha após {max_retries} tentativas. Pulando este livro.\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fN07bQET4Xn"
      },
      "outputs": [],
      "source": [
        "# Função para formatar o texto de cada livro\n",
        "def format_book_text(book):\n",
        "    if not isinstance(book, dict):\n",
        "        print(f\"Erro: Livro inválido: {book}\")\n",
        "        return \"\"\n",
        "    titulo = book.get(\"titulo\", \"\")\n",
        "    autor = book.get(\"autor\", \"\")\n",
        "    coautor = book.get(\"co-autor\", \"\")\n",
        "    idioma = book.get(\"idioma\", \"\")\n",
        "    pais = book.get(\"pais\", \"\")\n",
        "    itype = book.get(\"itype\", \"\")\n",
        "    nome_comum = \", \".join(book.get(\"nome_comum\", [])) if isinstance(book.get(\"nome_comum\"), list) else \"\"\n",
        "    shelvingloc = book.get(\"shelvingloc\", \"\")\n",
        "    call_no = book.get(\"call_no\", \"\")\n",
        "\n",
        "    text = f\"\"\"\n",
        "Título: {titulo}\n",
        "Autor: {autor}\n",
        "Co-autor: {coautor}\n",
        "Idioma: {idioma}\n",
        "País: {pais}\n",
        "Tipo: {itype}\n",
        "Assuntos: {nome_comum}\n",
        "Localização: {shelvingloc}\n",
        "Cota: {call_no}\n",
        "\"\"\"\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRhklTopTCH2",
        "outputId": "2266b200-d171-43aa-8d47-04d6784b82b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando dados do arquivo JSON...\n",
            "Total de livros carregados: 18266\n",
            "Carregado progresso parcial: 18200 livros já processados.\n",
            "Gerando embeddings para cada livro com backoff...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/66 [00:01<01:49,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 18/66 [00:26<01:09,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 21/66 [00:32<01:12,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 23/66 [00:36<01:16,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 27/66 [00:43<01:06,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 29/66 [00:47<01:06,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 33/66 [00:54<00:56,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 45/66 [01:12<00:30,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 52/66 [01:23<00:19,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 58/66 [01:33<00:11,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 61/66 [01:38<00:08,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 65/66 [01:46<00:01,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit excedido. Tentativa 1/5. Aguardando 1.10 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 66/66 [01:49<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings gerados: 18266\n",
            "Dimensão de cada embedding: 1024\n",
            "Criando índice FAISS...\n",
            "Salvando embeddings, metadados e índice FAISS...\n",
            "Processo concluído! Arquivos salvos em: /content/drive/MyDrive/Colab Notebooks/projeto II V3/scrapyFiles/faiss_index\n",
            "Arquivos gerados:\n",
            "- book_embeddings.npy: Array NumPy contendo todos os embeddings\n",
            "- book_metadata.pkl: Arquivo pickle com metadados correspondentes\n",
            "- book_index.faiss: Índice FAISS para busca de similaridade\n"
          ]
        }
      ],
      "source": [
        "# Carregar dados do JSON\n",
        "print(\"Carregando dados do arquivo JSON...\")\n",
        "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
        "    books = json.load(f)\n",
        "\n",
        "print(f\"Total de livros carregados: {len(books)}\")\n",
        "\n",
        "# Carregar progresso parcial, se existir\n",
        "embeddings = []\n",
        "metadata = []\n",
        "try:\n",
        "    embeddings_array = np.load(os.path.join(OUTPUT_DIR, \"book_embeddings_temp.npy\"))\n",
        "    with open(os.path.join(OUTPUT_DIR, \"book_metadata_temp.pkl\"), \"rb\") as f:\n",
        "        metadata = pickle.load(f)\n",
        "    embeddings = embeddings_array.tolist()\n",
        "    processed_ids = {m[\"id\"] for m in metadata}\n",
        "    books = [b for b in books if b.get(\"id\") not in processed_ids]\n",
        "    print(f\"Carregado progresso parcial: {len(embeddings)} livros já processados.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Nenhum progresso parcial encontrado. Iniciando do zero.\")\n",
        "\n",
        "# Gerar embeddings para cada livro\n",
        "print(\"Gerando embeddings para cada livro com backoff...\")\n",
        "try:\n",
        "    for book in tqdm(books, total=len(books)):\n",
        "        book_text = format_book_text(book)\n",
        "        embedding = get_embedding_with_retry(book_text)\n",
        "\n",
        "        if embedding:\n",
        "            embeddings.append(embedding)\n",
        "            book_metadata = {\n",
        "                \"id\": book.get(\"id\", \"\"),\n",
        "                \"titulo\": book.get(\"titulo\", \"\"),\n",
        "                \"autor\": book.get(\"autor\", \"\"),\n",
        "                \"idioma\": book.get(\"idioma\", \"\"),\n",
        "                \"nome_comum\": book.get(\"nome_comum\", []),\n",
        "                \"shelvingloc\": book.get(\"shelvingloc\", \"\"),\n",
        "                \"call_no\": book.get(\"call_no\", \"\")\n",
        "            }\n",
        "            metadata.append(book_metadata)\n",
        "\n",
        "            # Salvamento incremental a cada 100 livros\n",
        "            if len(embeddings) % 100 == 0 and len(embeddings) > 0:\n",
        "                np.save(os.path.join(OUTPUT_DIR, \"book_embeddings_temp.npy\"), np.array(embeddings).astype('float32'))\n",
        "                with open(os.path.join(OUTPUT_DIR, \"book_metadata_temp.pkl\"), \"wb\") as f:\n",
        "                    pickle.dump(metadata, f)\n",
        "                print(f\"Checkpoint salvo: {len(embeddings)} livros processados.\")\n",
        "\n",
        "        time.sleep(BASE_WAIT_TIME)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nProcesso interrompido pelo usuário.\")\n",
        "    if len(embeddings) > 0:\n",
        "        print(\"Salvando progresso parcial...\")\n",
        "        np.save(os.path.join(OUTPUT_DIR, \"book_embeddings_temp.npy\"), np.array(embeddings).astype('float32'))\n",
        "        with open(os.path.join(OUTPUT_DIR, \"book_metadata_temp.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(metadata, f)\n",
        "        print(f\"Progresso parcial salvo: {len(embeddings)} livros processados.\")\n",
        "    raise\n",
        "\n",
        "# Converter lista de embeddings para numpy array e salvar\n",
        "if len(embeddings) > 0:\n",
        "    print(f\"Embeddings gerados: {len(embeddings)}\")\n",
        "    embeddings_array = np.array(embeddings).astype('float32')\n",
        "    print(f\"Dimensão de cada embedding: {embeddings_array.shape[1]}\")\n",
        "\n",
        "    # Criar índice FAISS\n",
        "    print(\"Criando índice FAISS...\")\n",
        "    dimension = embeddings_array.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings_array)\n",
        "\n",
        "    # Salvar os arquivos finais\n",
        "    print(\"Salvando embeddings, metadados e índice FAISS...\")\n",
        "    np.save(os.path.join(OUTPUT_DIR, \"book_embeddings.npy\"), embeddings_array)\n",
        "    with open(os.path.join(OUTPUT_DIR, \"book_metadata.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(metadata, f)\n",
        "    faiss.write_index(index, os.path.join(OUTPUT_DIR, \"book_index.faiss\"))\n",
        "\n",
        "    print(f\"Processo concluído! Arquivos salvos em: {OUTPUT_DIR}\")\n",
        "    print(\"Arquivos gerados:\")\n",
        "    print(\"- book_embeddings.npy: Array NumPy contendo todos os embeddings\")\n",
        "    print(\"- book_metadata.pkl: Arquivo pickle com metadados correspondentes\")\n",
        "    print(\"- book_index.faiss: Índice FAISS para busca de similaridade\")\n",
        "else:\n",
        "    print(\"Nenhum embedding foi gerado com sucesso. Nenhum arquivo foi salvo.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}