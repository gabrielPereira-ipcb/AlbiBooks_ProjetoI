# -*- coding: utf-8 -*-
"""Copy of Copy of indexMistralV2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NgFSExndEKRykxdV5qtm6_KDWLjQP_HN
"""

!pip install faiss-cpu

import json
import time
import os
import numpy as np
import pickle
import faiss
import requests
from tqdm import tqdm

from google.colab import userdata
MISTRAL_API_KEY = userdata.get('MISTRAL_KEY')# Substitua pela sua chave da Mistral

INPUT_FILE = "/content/drive/MyDrive/Colab Notebooks/projeto II V3/scrapyFiles/biblioteca_dados_combinado.json"
OUTPUT_DIR = "/content/drive/MyDrive/Colab Notebooks/projeto II V3/scrapyFiles/faiss_index"
EMBEDDING_DIM = 1024  # Dimensão dos embeddings do modelo Mistral
BASE_WAIT_TIME = 1.1  # Tempo base de espera entre requisições
MAX_RETRIES = 5      # Número máximo de tentativas para cada livro

# Função para gerar embeddings usando a API da Mistral com retry e backoff
def get_embedding_with_retry(text, api_key=MISTRAL_API_KEY, max_retries=MAX_RETRIES):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    url = "https://api.mistral.ai/v1/embeddings"
    payload = {
        "model": "mistral-embed",
        "input": text
    }

    # Implementar backoff
    for attempt in range(max_retries):
        try:
            response = requests.post(url, json=payload, headers=headers)

            if response.status_code == 200:
                return response.json()["data"][0]["embedding"]
            elif response.status_code == 429:
                # Rate limit exceeded, fazer backoff
                wait_time = BASE_WAIT_TIME * (2 ** attempt)
                print(f"Rate limit excedido. Tentativa {attempt+1}/{max_retries}. Aguardando {wait_time:.2f} segundos...")
                time.sleep(wait_time)
            else:
                print(f"Erro na API: {response.status_code}")
                print(response.text)
                # Esperar um pouco antes de tentar novamente
                time.sleep(BASE_WAIT_TIME)
        except Exception as e:
            print(f"Exceção ocorreu: {str(e)}")
            time.sleep(BASE_WAIT_TIME)

    print(f"Falha após {max_retries} tentativas. Pulando este livro.")
    return None

# Função para formatar o texto de cada livro
def format_book_text(book):
    # Tratar possíveis campos vazios
    titulo = book.get("titulo", "")
    autor = book.get("autor", "")
    coautor = book.get("co-autor", "")
    idioma = book.get("idioma", "")
    pais = book.get("pais", "")
    itype = book.get("itype", "")
    nome_comum = ", ".join(book.get("nome_comum", []))
    shelvingloc = book.get("shelvingloc", "")
    call_no = book.get("call_no", "")

    # Formatar o texto conforme especificado
    text = f"""
Título: {titulo}
Autor: {autor}
Co-autor: {coautor}
Idioma: {idioma}
País: {pais}
Tipo: {itype}
Assuntos: {nome_comum}
Localização: {shelvingloc}
Cota: {call_no}
"""
    return text.strip()

# Carregar dados do JSON
print("Carregando dados do arquivo JSON...")
with open(INPUT_FILE, 'r', encoding='utf-8') as f:
    books = json.load(f)

print(f"Total de livros carregados: {len(books)}")

# Inicializar listas para armazenar embeddings e metadados
embeddings = []
metadata = []

# Gerar embeddings para cada livro
print("Gerando embeddings para cada livro com backoff...")
try:
    for book in tqdm(books, total=len(books)):
        # Formatar o texto do livro
        book_text = format_book_text(book)

        # Gerar embedding com retry
        embedding = get_embedding_with_retry(book_text)

        # Se conseguiu gerar o embedding com sucesso
        if embedding:
            embeddings.append(embedding)

            # Guardar metadados relevantes
            book_metadata = {
                "id": book.get("id", ""),
                "titulo": book.get("titulo", ""),
                "autor": book.get("autor", ""),
                "idioma": book.get("idioma", ""),
                "nome_comum": book.get("nome_comum", []),
                "shelvingloc": book.get("shelvingloc", ""),
                "call_no": book.get("call_no", "")
            }
            metadata.append(book_metadata)

        # Aguardar tempo base entre requisições (mesmo com sucesso)
        time.sleep(BASE_WAIT_TIME)
except KeyboardInterrupt:
    print("\nProcesso interrompido pelo usuário.")
    if len(embeddings) > 0:
        print("Há embeddings parciais gerados, mas nenhum arquivo será salvo conforme solicitado.")
    raise

# Converter lista de embeddings para numpy array e salvar apenas no final
if len(embeddings) > 0:
    print(f"Embeddings gerados: {len(embeddings)}")
    embeddings_array = np.array(embeddings).astype('float32')
    print(f"Dimensão de cada embedding: {embeddings_array.shape[1]}")

    # Criar índice FAISS
    print("Criando índice FAISS...")
    dimension = embeddings_array.shape[1]  # Dimensão dos embeddings
    index = faiss.IndexFlatL2(dimension)   # Índice L2 (distância euclidiana)
    index.add(embeddings_array)            # Adicionar embeddings ao índice

    # Salvar os embeddings, metadados e índice FAISS APENAS NO FINAL
    print("Salvando embeddings, metadados e índice FAISS...")

    # Salvar embeddings como arquivo numpy
    np.save(os.path.join(OUTPUT_DIR, "book_embeddings.npy"), embeddings_array)

    # Salvar metadados como pickle
    with open(os.path.join(OUTPUT_DIR, "book_metadata.pkl"), "wb") as f:
        pickle.dump(metadata, f)

    # Salvar índice FAISS
    faiss.write_index(index, os.path.join(OUTPUT_DIR, "book_index.faiss"))

    print(f"Processo concluído! Arquivos salvos em: {OUTPUT_DIR}")
    print("Arquivos gerados:")
    print("- book_embeddings.npy: Array NumPy contendo todos os embeddings")
    print("- book_metadata.pkl: Arquivo pickle com metadados correspondentes")
    print("- book_index.faiss: Índice FAISS para busca de similaridade")
else:
    print("Nenhum embedding foi gerado com sucesso. Nenhum arquivo foi salvo.")

# Código adicional para testar o índice (opcional)
def test_search(query_text, top_k=5):
    print(f"\nTestando busca para: '{query_text}'")

    # Gerar embedding para a consulta
    query_embedding = get_embedding(query_text)
    if not query_embedding:
        print("Erro ao gerar embedding para consulta")
        return

    # Converter para array numpy
    query_embedding_array = np.array([query_embedding]).astype('float32')

    # Buscar no índice FAISS
    distances, indices = index.search(query_embedding_array, top_k)

    # Mostrar resultados
    print(f"\nResultados mais similares:")
    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
        print(f"{i+1}. {metadata[idx]['titulo']} (Autor: {metadata[idx]['autor']}) - Distância: {dist:.4f}")

# Descomente para testar o índice com uma consulta específica
# test_search("agricultura sustentável em Portugal")